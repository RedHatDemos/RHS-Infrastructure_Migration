:scrollbar:
:data-uri:
:toc2:
:imagesdir: images

== Infrastructure Migration 1.2 GA - Migration Guide

:numbered:

== Overview

This Lab Environment uses Red Hat CloudForms, and the Infrastructure Migration plugin (a.k.a. v2v-plugin) included with it, as a broker to migrate VMs from VMware vSphere to Red Hat Virtualization (RHV). During the migration, supported OSes can be converted to RHEL and get registered to Satellite for seamless management automatically. 

The password and user accounts to access all services is provided by the lab administrators.

In this environment the following configuration steps are already done:

* Configure the conversion hosts in the target provider (Red Hat Virtualization)
* Provide credentials for virtualization providers and conversion hosts in CloudForms
* Assign tags for the conversion hosts in CloudForms
* Configured Ansible hosts file in `workstation` and ssh keys exchanged (`/root/.ssh/id_rsa`)

The providers are:

* Source - VMware vSphere
* Target - Red Hat Virtualization

Infrastructure management provided by:

* Red Hat Satellite 6.6
* CloudForms Management Engine

After this initial step, the resource equivalence between the two providers, involved in each migration, has to be defined in an *Infrastucture Mapping* including:

* Clusters
* Storage Domains
* Networks

To perform the migration one *Conversion Host* has been configured for the target provider.

* In the RHV case the one of the RHEL hypervisors is configured as conversion host

Finally, a *Migration Plan* has to be executed to perform the final migration.

.Goal
* Migrate and convert several VMs from VMware vSphere to Red Hat Virtualization, using Red Hat CloudForms as a broker, with the tooling included in the Red Hat Infrastructure Migration Solution
+
NOTE: The source VMs are not deleted, only powered off once the migration is done. This measure can also be used as "rollback" in case a migration failure occurs.

Versions of products used:

[cols="1,1",options="header"]
|=======
|Product |Version
|CloudForms |5.11.0
|Red Hat Virtualization |4.3.3
|Red Hat Enterprise Linux (Conversion Host) |7.6+
|Conversion Host Image |1.7+
|VMware vSphere |6.7
|=======

== Requirements to access and perform this lab

=== Base requirements

* A computer with access to the Internet :-)
* SSH client (for Microsoft Windows users, link:https://www.putty.org/[Putty] application or built-in bash in Windows 10 are both good choices)
* Firefox 17 or higher, or Chromium / Chrome
+
[NOTE]
Grammarly plugin for Chrome may cause problems when managing CloudForms. Please deactivate it while doing this lab.

== Environment

A full new migration environment is deployed on every request. To make the environment unique a 4 character identifier is assigned to it (i.e. `1e37`), this identifier is referred in this documentation as *YOUR-GUID*.

The migration environment consists of the following systems:

image::blueprint1.png[Blueprint]


[cols="1,1,1,2",options="header"]
|=======
| Hostname | Internal IP | External name | Description
|`workstation.example.com` |`192.168.0.10` | workstation-<YOUR-GUID>.rhpds.opentlc.com |Jump host and Ansible host
|`storage.example.com` |`192.168.0.254` | workstation-<YOUR-GUID>.rhpds.opentlc.com | NFS server
|`cf.example.com` |`192.168.0.100` |  cf-<YOUR-GUID>.rhpds.opentlc.com |CloudForms server
|`satellite.example.com` |`192.168.0.31` |  satellite-<YOUR-GUID>.rhpds.opentlc.com |Satellite 6.6 server
|`rhvm.example.com` |`192.168.0.35` | rhvm-<YOUR-GUID>.rhpds.opentlc.com |Red Hat Virtualization Manager server
|`kvm1.example.com` |`192.168.0.41` | kvm1-<YOUR-GUID>.rhpds.opentlc.com |KVM hypervisor managed by Red Hat Virtualization
|`kvm2.example.com` |`192.168.0.42` | kvm2-<YOUR-GUID>.rhpds.opentlc.com |KVM hypervisor managed by Red Hat Virtualization
|`vcenter.example.com` |`192.168.0.50` | vcenter-<YOUR-GUID>.rhpds.opentlc.com |VMware vCenter server
|`esx1.example.com` |`192.168.0.51` | N/A |ESXi hypervisor
|`esx2.example.com` |`192.168.0.52` | N/A |ESXi hypervisor
|=======


The architecture of the deployment can be depicted with the following image:

image::architecture_diagram1.png[Architecture Diagram]

* Networks used in the environment

[cols="1,1,2",options="header"]
|=======
| Network Name | IP range | Description
| `Admin` | `192.168.x.x/16` | General administration and storage network.
| `Service` | `10.10.0.x/24` | Internal network for the VMs delivering services to users.
|=======

* Virtual Machines
+
This deployment of the migration environment includes the following VMs provisioned and running in the vSphere environment in order to be migrated:

[cols="1,1,2",options="header"]
|=======
| Name | IPs | Description
| `hana.example.com` | 10.10.0.130 | Red Hat Enterprise Linux 7 host running SAP HANA on .
| `oracledb.example.com` | 10.10.0.160 | Oracle DB running on Oracle Linux 7 host.
| `tomcat.example.com` | 10.10.0.180 | CentOS Linux 7 host running Tomcat.
|=======

{sp}+

== Getting Started

. Once the system is running, use SSH to access your bastion workstation using `lab-user`.

+
----
$ ssh lab-user@workstation-<YOUR-GUID>.rhpds.opentlc.com
----

. Become `root` using the provided password:
+
----
$ sudo -i
----

. Check the status of the whole environment, from the `workstation`, using ansible:
+
----
# ansible all -m ping
----
+
This command establishes a connection to all the machines in the environment (except ESXi servers).
In case the machines are up an running a success message, per each, will show up.
This is an example of a success message for the VM `cf.example.com`:
+
----
cf.example.com | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
----
+
To check the infrastructure machines the following command can be also used:
+
----
# ansible infra -m ping
----
+
[NOTE]
As this environment is quite big, and it is generated and powered up for you in a cloud environment, some resources may suffer from issues or delays depending on the status of the cloud. You may need to manually start up or reboot some of them. Please review everything is running before proceeding forward.

. Establish an SSH connection to the CloudForms server and monitor `automation.log`:
+
----
# ssh cf.example.com
# tail -f /var/www/miq/vmdb/log/automation.log
----
+
[TIP]
The log entries are very long, so it helps if you stretch this window as wide as possible.
+
[NOTE]
The log entries can be also seen in the CloudForms web UI in *Automation -> Automate -> Log*.

. Prepare to manage the environment. 
From a web browser, open each of the URLs below in its own window or tab, using these credentials (except when noted):

* *Username*: `admin`
* *Password*: `<to_be_provided>`
+
[NOTE]
You must accept all of the self-signed SSL certificates.
+

* *Red Hat Virtualization Manager:* `*\https://rhvm-<YOUR-GUID>.rhpds.opentlc.com*`
.. Navigate to and click *Administration Portal* and log in using `admin`, `<to_be_provided>`, and `internal`.
+
image::rhv_login.png[RHV Login]

.. Verify that the Cluster is up and Hypervisors are active
+
[TIP]
As this is nested virtualization, sometimes the CPU type of the hypervisor is changed.
+
image::rhv_hypervisors_up.png[RHV Hypervisors up]

* *vCenter:* `*\https://vcenter-<YOUR-GUID>.rhpds.opentlc.com*`
+
image::vsphere_web_client_0.png[vCenter Login]

+
* Click on *LAUNCH VSPHERE CLIENT (HTML5)* to get to the login screen
+
image::vsphere_web_client_1.png[vSphere Web Client Login]
+
[WARNING]
Use `administrator@vsphere.local` as the username to log in to vCenter.

* Click *Click on VMs and Templates*.
+
image::vsphere_web_client_2.png[vCenter]

.. Click *VMs and Templates*, expand the Datacenter on the left pane, and verify that the 3 VMs `hana`, `oracledb` and `tomcat` are running.
+
image::vsphere_web_client_3.png[vCenter]

* *CloudForms:* `*\https://cf-<YOUR-GUID>.rhpds.opentlc.com*`
+
image::cloudforms_login.png[CloudForms Login]
+

After logging in you will be presented with the CloudForms Dashboard.
+
image::cloudforms_dashboard.png[CloudForms Dashboard]

=== Validate the Current Infrastructure in CloudForms

. Log in with user `admin` and the provided password in CloudForms. Once in the web interface, go to *Compute -> Infrastructure -> Providers*.
+
image::cloudforms_infrastructure_providers_1.png[CloudForms Infrastructure Providers 1]

. You should see a green tick mark in the provider boxes as shown in the screenshot below. 
If you by any chance, see an exclamation mark (*!*), or a cross ([red]#*x*#) in a provider, check the provider's box, go to *Authentication -> Re-check Authentication Status*.
+
image::cloudforms_infrastructure_providers_2.png[CloudForms Infrastructure Providers 2]

. To have proper information on all the resources available, check the provider's box, go to *Configuration -> Refresh Relationships and Power States*.
+
image::cloudforms_infrastructure_providers_4.png[CloudForms Infrastructure Providers 4]
+

. Go to *Compute -> Infrastructure -> Virtual Machines -> All VMs & Templates*.
+
image::cloudforms_vms_1.png[CloudForms Virtual Machines 1]

. All VMs, Orphaned VMs and Templates in both RHV and vSphere show as entities in CloudForms.
We can currently see the VMs deployed and running, as well as the ones which are shut down within our environment. 
+
image::cloudforms_vms_2.png[CloudForms Virtual Machines 2]
+
[NOTE]
If you had to initiate the re-validion of the providers in previous steps, you may have to wait a few minutes and refresh the screen before the VMs show up.

== Create an Infrastructure Mapping (vSphere to RHV)

. Navigate to the *Migration -> Infrastructure Mappings*.
+
image::infrastructure_mapping_0.png[Infrastructure Mapping 1]

. Click on *Create Infrastructure Mapping*.
+
image::infrastructure_mapping_1.png[Infrastructure Mapping 2]

. In the *step 1* of the wizard, *General*, type the name `VMware to RHV`, select as *Target Provider* `Red Hat Virtualization`  and click *Next*.
+
* A description may be added to make it easy to, later on, recognize the usage of the mapping.
+
image::infrastructure_mapping_3.png[Infrastructure Mapping 3]

. In the *step 2* of the wizard, *Map Compute*, select *Source Provider \ Datacenter \ Cluster* as `vSphere\Datacenter\VMCluster` and *Target Provider \ Datacenter \ Cluster* as `RHV\CoolDataCenter\TrustedCluster` and click *Add Mapping*, then click *Next*.
+
image::infrastructure_mapping_4.png[Infrastructure Mapping 4]

. In the *step 3* of the wizard, *Map Storage*, and having selected *Cluster01 (TrustedCluster)* as the cluster to work with, select *Source Provider \ Datacenter \ Datastore* as `vSphere\Datacenter\NFS-Storage` and *Target Datastores* as `RHV\VMStorageNFS` and click *Add Mapping*, then click *Next*.
+
image::infrastructure_mapping_5.png[Infrastructure Mapping 5]

. In the *step 4* of the wizard, *Map Networks*, *Cluster01 (TrustedCluster)* will be selected as the cluster to work with. 
We will start by mapping the network used by VMs to connect to each other. This describes which source networks on VMware map to the destination
network after the migration to RHV. 
We select *Source Provider \ Datacenter \ Network* as `vSphere \ Datacenter \ Net-Service` and *Target Network* as `RHV\service` and click *Add Mapping*.
+
image::infrastructure_mapping_6a.png[Infrastructure Mapping 6]
+
* We will continue by mapping the network used by VMs to expose services to the internet. We select *Source Provider \ Datacenter \ Network* as `vSphere\Datacenter\Net-Service-DMZ` and *Target Network* as `RHV\service-dmz` and click *Add Mapping*.
+
image::infrastructure_mapping_6b.png[Infrastructure Mapping 6]
+
* Finally we can map the management network. To do so, select *Source Provider \ Datacenter \ Network* as `vSphere\Datacenter\Net-Management` and *Target Network* as `RHV\ovirtmgmt` and click *Add Mapping*, then click *Create*.
+
image::infrastructure_mapping_6.png[Infrastructure Mapping 6]

. In the *step 5* of the wizard, *Results*, a message `All mappings in VMware to RHV have been mapped.` will appear. 
 The only thing left to do is to click on *Close* on the last page of the wizard.
After the wizard closes, you will be presented with a finished mapping, as shown in the next screenshot.
+
image::infrastructure_mapping_8.png[Infrastructure Mapping 8]

In these steps an *Infrastructure Mapping* has been created in order to simplify source and target resources using the data collected by Red hat CloudForms from both VMware vSphere and Red Hat Virtualization.

== Migrating VMs to RHV with a Migration Plan

=== Create the migration plan

. Start in the CloudForms page accessed by navigating to *Migration -> Migration Plans*.
+
image::migration_plan_0.png[Migration Plan 0]

. Click on *Create Migration Plan*.
+
image::migration_plan_1.png[Migration Plan 1]

. In the *step 1* of the wizard, *General*, select in the drop down menu the *Infrastructure Mapping* to be used, `VMware to RHV`, add the name `Summit 2020 Lab` and click *Next*.
+
image::migration_plan_2.png[Migration Plan 2]
+
[NOTE]
Keeping the default option will take us to the VM menu selector. 
For massive conversions, there is an option to use a CSV file upload which may be a better choice.

. In the *step 2* of the wizard, *VMs*, we will choose the 3 VMs to be migrated to RHV. 
Please select *hana*, *oracledb* and *tomcat*  virtual machines, as the ones to be migrated.
+
image::migration_plan_3.png[Migration Plan 3]
+
[NOTE]
VM selector has a filter to help find a set of VMs within a long list. We may try filtering by the term `tomcat` for example.

. In the *step 3* of the wizard, *Advanced Options*, we can assign *Pre* and *Post* migration playbooks to be executed during the migration. 
Since we have two servers which are running distributions we would like to convert to RHEL during the conversion, we will enable *post* playbooks for those. 
Click on a *Select postmigration playbook service* drop-down and choose `PostMigration - Convert2RHEL`

+
image::migration_plan_4.png[Migration Plan 4]

In the same step make sure we select the VMs that need to be converted. Those are `oracledb` ( currently running Oracle Linux) and `tomcat` ( currently running CentOS).

image::migration_plan_4a.png[Migration Plan 4a]

. In the *step 4* of the wizard, *Schedule*, select *Start migration immediately* and click *Create*.
The wizard will close and the migration of the VMs will start immediately. 
+
image::migration_plan_5.png[Migration Plan 5]

[NOTE]
The migration plan can be scheduled to be ran at a later time, by choosing the other option.

. In the *step 5* of the wizard, *Results*, the message `Migration Plan: 'Summit 2020 Lab' is in progress` will be displayed. Click *Close*.
+
image::migration_plan_6.png[Migration Plan 6]

=== Monitor the Migration

. As soon as you clicked close, you would be presented with a page showing the migration plans In Progress
+
image::migration_running_3.png[Migration Running 3]

. Now the migration is executing. It takes some time for the pre-migration steps to be finished and the conversion process to start.
If we wished to, we can see the orchestration process in CloudForms logs.
From the workstation terminal you can SSH into CloudForms and tail the logs. 
Word of caution: the automation.log is storing a lot of logs and can present a huge amount of scrolling text. 
+
----
# ssh cf.example.com
# tail -f /var/www/miq/vmdb/log/automation.log
----
+
Once the pre-migration steps are finished and the conversion starts, each VM conversion process can be tracked in the Conversion Host.
Our conversion hosts are kvm1 and kvm2. So, for example we could do:
+
----
# ssh kvm1.example.com
# [root@kvm1 ~]# tail -f /var/log/vdsm/import/v2v-import-*.log
----

. CloudForms Migration interface shows migration status too.
Clicking on the running plan info box with the name `Summit 2020 Lab` will display the detailed info of the status:
+
image::migration_running_5.png[Migration Running 5]

. The total migration of our VMs will take approximately `55-60` minutes, depending on the load on the cloud servers supporting the environment.
Post-migration playbooks should start in about 19 minutes for the first VM. 
The VMs being migrated will be powered off for the cold migration. + 
It is possible to check in the *RHV* admin portal under *Compute -> Virtual Machines* to monitor the status for the VM import as part of the migration process.
If the VM list is empty, it means that none of the VMs have been created in the destination yet. The disk conversion is running however and the VMs will start showing up sequentially after the disk conversion has been completed. + 
In about 30 minutes you will see different VMs having a different stage of migration. Completing post migration playbooks, or powering on. 

+
image::migration_running_8.png[Migration Running 8]

. These machines will be now visible in the WEB UI of the Red Hat Virtualization as well as powered on and running. 
+
image::migration_running_9.png[Migration Running 9]

. The RHEL VM, `hana` has been migrated, while the `tomcat` are running their Convert2RHEL plabooks, and are being registered to Satellite. 
+
image::migration_running_10.png[Migration Running 10]

. The last of the VMs is powered on inside RHV and is being converted to RHEL as well
+
image::migration_running_11.png[Migration Running 11]

. CloudForms is now showing us that the migration has been completed successfully. 
The final view of the Migration Page should look something like this:
+
image::migration_running_finish.png[Migration Finished]

. Let's check if the VMs are up and running using the following command:
+
----
# [root@workstation-repl ~]# ansible apps -m ping
hana.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false,
    "ping": "pong"
}
oracledb.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false,
    "ping": "pong"
}
tomcat.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false,
    "ping": "pong"
}
----

. Migration can be reviewed in the Main Migration page in CloudForms
+
image::migration_running_finish2.png[Migration Running 15]

. Additionally the migration log can be downloaded and accessed post VM migration. This is useful for troubleshooting errors or just to check the migration details. It's worth mentioning that if the migration fails prior to the VM being migrated this log will not be available. The logs are in plain text format. +
To access the log navigate to Completed Plans, and click **Download Log** and then **Migration log** next to the desired VM.
+
image::migration_log.png[Migration Log Access]



