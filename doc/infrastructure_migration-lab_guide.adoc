:scrollbar:
:data-uri:
:toc2:
:imagesdir: images

== Infrastructure Migration 1.2 GA - Migration Guide

:numbered:

== Overview

This Lab Environment uses Red Hat CloudForms, and the Infrastructure Migration plugin (a.k.a. v2v-plugin) included with it, as a broker to migrate VMs from VMware vSphere to Red Hat Virtualization (RHV). During the migration, supported OSes can be converted to RHEL and get registered to Satellite for seamless management automatically. 

The password and user accounts to access all services is provided by the lab administrators.

In this environment the following configuration steps are already done:

* Configure the conversion hosts in the target provider (Red Hat Virtualization)
* Provide credentials for virtualization providers and conversion hosts in CloudForms
* Assign tags for the conversion hosts in CloudForms
* Configured Ansible hosts file in `workstation` and ssh keys exchanged (`/root/.ssh/id_rsa`)

The providers are:

* Source - VMware vSphere
* Target - Red Hat Virtualization

Infrastructure management provided by:

* Red Hat Satellite 6.6
* CloudForms Management Engine

After this initial step, the resource equivalence between the two providers, involved in each migration, has to be defined in an *Infrastucture Mapping* including:

* Clusters
* Storage Domains
* Networks

To perform the migration one *Conversion Host* has been configured for the target provider.

* In the RHV case the one of the RHEL hypervisors is configured as conversion host

Finally, a *Migration Plan* has to be executed to perform the final migration.

.Goal
* Migrate and convert several VMs from VMware vSphere to Red Hat Virtualization, using Red Hat CloudForms as a broker, with the tooling included in the Red Hat Infrastructure Migration Solution
+
NOTE: The source VMs are not deleted, only powered off once the migration is done. This measure can also be used as "rollback" in case a migration failure occurs.

Versions of products used:

[cols="1,1",options="header"]
|=======
|Product |Version
|CloudForms |5.11.0
|Red Hat Virtualization |4.3.3
|Red Hat Enterprise Linux (Conversion Host) |7.6+
|Conversion Host Image |1.7+
|VMware vSphere |6.7
|=======

== Requirements to access and perform this lab

=== Base requirements

* A computer with access to the Internet :-)
* SSH client (for Microsoft Windows users link:https://www.putty.org/[Putty] or built-in bash in Windows 10 can be used)
* Firefox 17 or higher, or Chromium / Chrome
+
[NOTE]
Grammarly plugin for Chrome may cause problems when managing CloudForms. Please deactivate it while doing this lab.

== Environment

A full new migration environment is deployed on every request. To make the environment unique a 4 character identifier is assigned to it (i.e. `1e37`), this identifier is referred in this documentation as *YOUR-GUID*.

The migration environment consists of the following systems:

image::blueprint1.png[Blueprint]


[cols="1,1,1,2",options="header"]
|=======
| Hostname | Internal IP | External name | Description
|`workstation.example.com` |`192.168.0.10` | workstation-<YOUR-GUID>.rhpds.opentlc.com |Jump host and Ansible host
|`storage.example.com` |`192.168.0.254` | workstation-<YOUR-GUID>.rhpds.opentlc.com | NFS server
|`cf.example.com` |`192.168.0.100` |  cf-<YOUR-GUID>.rhpds.opentlc.com |CloudForms server
|`satellite.example.com` |`192.168.0.31` |  satellite-<YOUR-GUID>.rhpds.opentlc.com |Satellite 6.6 server
|`rhvm.example.com` |`192.168.0.35` | rhvm-<YOUR-GUID>.rhpds.opentlc.com |Red Hat Virtualization Manager server
|`kvm1.example.com` |`192.168.0.41` | kvm1-<YOUR-GUID>.rhpds.opentlc.com |KVM hypervisor managed by Red Hat Virtualization
|`kvm2.example.com` |`192.168.0.42` | kvm2-<YOUR-GUID>.rhpds.opentlc.com |KVM hypervisor managed by Red Hat Virtualization
|`vcenter.example.com` |`192.168.0.50` | vcenter-<YOUR-GUID>.rhpds.opentlc.com |VMware vCenter server
|`esx1.example.com` |`192.168.0.51` | N/A |ESXi hypervisor
|`esx2.example.com` |`192.168.0.52` | N/A |ESXi hypervisor
|=======


The architecture of the deployment can be depicted with the following image:

***Add Some Architecture image here***

* Networks used in the environment

[cols="1,1,2",options="header"]
|=======
| Network Name | IP range | Description
| `Admin` | `192.168.x.x/16` | General administration and storage network.
| `Service` | `10.10.0.x/24` | Internal network for the app to connect LB to EAP and to DB.
| `Servicer-DMZ` | `10.9.0.x/24` | External DMZ network to publish the app. Also access to the user API for OSP and Horizon (provider network)
|=======

* Virtual Machines
+
This deployment of the migration environment includes the following VMs provisioned and running in the vSphere environment in order to be migrated:

[cols="1,1,2",options="header"]
|=======
| Name | IPs | Description
| `hana.example.com` | 10.10.0.130 | Red Hat Enterprise Linux 7 host running SAP HANA on .
| `oracledb.example.com` | 10.10.0.160 | Oracle DB running on Oracle Linux 7 host.
| `tomcat.example.com` | 10.10.0.180 | CentOS Linux 7 host running Tomcat.
|=======

{sp}+

== Getting Started

. Once the system is running, use SSH to access your bastion workstation using `lab-user`.

+
----
$ ssh lab-user@workstation-<YOUR-GUID>.rhpds.opentlc.com
----

. Become `root` using the provided password:
+
----
$ sudo -i
----

. Check the status of the whole environment, from the `workstation`, using ansible:
+
----
# ansible all -m ping
----
+
This command establishes a connection to all the machines in the environment (except ESXi servers).
In case the machines are up an running a success message, per each, will show up.
This is an example of a success message for the VM `cf.example.com`:
+
----
cf.example.com | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
----
+
To check the infrastructure machines the following command can be also used:
+
----
# ansible infra -m ping
----
+
[NOTE]
As this environment is quite big, and it is generated and powered up for you in a cloud environment, some resources may suffer from issues or delays depending on the status of the cloud. You may need to manually start up or reboot some of them. Please review everything is running before proceeding forward.

. Establish an SSH connection to the CloudForms server and monitor `automation.log`:
+
----
# ssh cf.example.com
# tail -f /var/www/miq/vmdb/log/automation.log
----
+
[TIP]
The log entries are very long, so it helps if you stretch this window as wide as possible.
+
[NOTE]
The log entries can be also seen in the CloudForms web UI in *Automation -> Automate -> Log*.

. Prepare to manage the environment. From a web browser, open each of the URLs below in its own window or tab, using these credentials (except when noted):

* *Username*: `admin`
* *Password*: `<to_be_provided>`
+
[NOTE]
You must accept all of the self-signed SSL certificates.
+
[TIP]
The password `to_be_provided` is the same one previously specified

* *Red Hat Virtualization Manager:* `*\https://rhvm-<YOUR-GUID>.rhpds.opentlc.com*`
.. Navigate to and click *Administration Portal* and log in using `admin`, `<to_be_provided>`, and `internal`.
+
image::rhv_login.png[RHV Login]

.. Verify that the Cluster is up and Hypervisors are active
+
[TIP]
As this is nested virtualization, sometimes the CPU type of the hypervisor is changed.
+
image::rhv_hypervisors_up.png[RHV Hypervisors up]

* *vCenter:* `*\https://vcenter-<YOUR-GUID>.rhpds.opentlc.com*`
+
image::vsphere_web_client_0.png[vCenter Login]

+
* Click on *Log in to vSphere Web Client*
+
image::vsphere_web_client_1.png[vSphere Web Client Login]
+
[WARNING]
Use `root` as the username to log in to vCenter.

* Click *Click on VMs and Templates*.
+
image::vsphere_web_client_2.png[vCenter]

.. Click *VMs and Templates* and verify that the 4 VMs `lb.example.com`, `jboss0.example.com`, `jboss1.example.com` and `db.example.com` are running.
+
image::vsphere_web_client_3.png[vCenter]

* *CloudForms:* `*\https://cf-<YOUR-GUID>.rhpds.opentlc.com*`
+
image::cloudforms_login.png[CloudForms Login]
+

After logging in you will be presented with the CloudForms Dashboard.
+
image::cloudforms_dashboard.png[CloudForms Dashboard]

=== Validate the Current Infrastructure in CloudForms

. Log in with user `admin` and the provided password in CloudForms. Once in the web interface, go to *Compute -> Infrastructure -> Providers*.
+
image::cloudforms_infrastructure_providers_1.png[CloudForms Infrastructure Providers 1]

. If you see an exclamation mark (*!*), or a cross (*x*) in a provider, check the provider's box, go to *Authentication -> Re-check Authentication Status*.
+
image::cloudforms_infrastructure_providers_2.png[CloudForms Infrastructure Providers 2]
+
image::cloudforms_infrastructure_providers_3.png[CloudForms Infrastructure Providers 3]
+

. To have proper information on all the resources available, check the provider's box, go to *Configuration -> Refresh Relationships and Power States*.
+
image::cloudforms_infrastructure_providers_4.png[CloudForms Infrastructure Providers 4]
+
image::cloudforms_infrastructure_providers_5.png[CloudForms Infrastructure Providers 5]

. Go to *Compute -> Infrastructure -> Virtual Machines -> All VMs & Templates*.
+
image::cloudforms_vms_1.png[CloudForms Virtual Machines 1]

. All VMs, Orphaned VMs and Templates in both RHV and vSphere show as entities in CloudForms.
+
image::cloudforms_vms_2.png[CloudForms Virtual Machines 2]
+
[NOTE]
If you needed to validate providers, you may have to wait a few minutes and refresh the screen before the VMs show up.

. Select the pane *VMs & Templates* and, in it, the *vSphere* provider.

. Only the VMs and Templates in vSphere will show.
+
image::cloudforms_vms_3.png[CloudForms Virtual Machines 3]
+
[TIP]
This is a good way to check that the app VMs are up and running and start the stopped ones.


== Create an Infrastructure Mapping (vSphere to RHV)

. Navigate to the *Compute -> Migration -> Infrastructure Mappings*.
+
image::infrastructure_mapping_1.png[Infrastructure Mapping 1]

. Click on *Create Infrastructure Mapping*.
+
image::infrastructure_mapping_2.png[Infrastructure Mapping 2]

. In the *step 1* of the wizard, *General*, type the name `ticket-monster-map-rhv`, select as *Target Provider* `Red Hat Virtualization`  and click *Next*.
+
* A description may be added to make it easy to, later on, recognize the usage of the mapping.
+
image::infrastructure_mapping_3.png[Infrastructure Mapping 3]

. In the *step 2* of the wizard, *Map Compute*, select *Source Provider \ Datacenter \ Cluster* as `vSphere\DC01\Cluster01` and *Target Provider \ Datacenter \ Cluster* as `RHV\CoolDataCenter\TrustedCluster` and click *Add Mapping*, then click *Next*.
+
image::infrastructure_mapping_4.png[Infrastructure Mapping 4]

. In the *step 3* of the wizard, *Map Storage*, and having selected *Cluster01 (TrustedCluster)* as the cluster to work with, select *Source Provider \ Datacenter \ Datastore* as `vSphere\DC01\Datastore` and *Target Datastore* as `RHV\VMStorageNFS` and click *Add Mapping*, then click *Next*.
+
image::infrastructure_mapping_5.png[Infrastructure Mapping 5]

. In the *step 4* of the wizard, *Map Networks*, and having selected *Cluster01 (TrustedCluster)* as the cluster to work with. We will start by mapping the network used by VMs to connect to each other (i.e. JBoss EAP to the Database). We select *Source Provider \ Datacenter \ Network* as `vSphere\DC01\App-Internal-DPortGroup` and *Target Network* as `RHV\service` and click *Add Mapping*.
+
image::infrastructure_mapping_6a.png[Infrastructure Mapping 6]
+
* We will continue by mapping the network used by VMs to expose services to the internet(i.e. the Load Balancer exposing the Ticket Monster app). We select *Source Provider \ Datacenter \ Network* as `vSphere\DC01\App-DMZ-DPortGroup` and *Target Network* as `RHV\service-dmz` and click *Add Mapping*.
+
image::infrastructure_mapping_6b.png[Infrastructure Mapping 6]
+
* Finally we can map the management network. To do so, select *Source Provider \ Datacenter \ Network* as `vSphere\DC01\Management Network` and *Target Network* as `RHV\ovirtmgmt` and click *Add Mapping*, then click *Create*.
+
image::infrastructure_mapping_6.png[Infrastructure Mapping 6]
+
* This is what the final network mapping should look like
+
image::infrastructure_mapping_6c.png[Infrastructure Mapping 6]


. In the *step 5* of the wizard, *Results*, a message `All mappings in ticket-monster-map-rhv have been mapped.` shall appear. Click *Close*.
+
image::infrastructure_mapping_7.png[Infrastructure Mapping 7]
+
image::infrastructure_mapping_8.png[Infrastructure Mapping 8]

In these steps an *Infrastructure Mapping* has been created in order to simplify source and target resources using the data collected by Red hat CloudForms from both VMware vSphere and Red Hat Virtualization.

== Migrating VMs to RHV with a Migration Plan

=== Create the migration plan

. Start in the CloudForms page accessed by navigating to *Compute -> Migration -> Migration Plans*.
+
image::migration_plan_0.png[Migration Plan 0]

. Click on *Create Migration Plan*.
+
image::migration_plan_1.png[Migration Plan 1]

. In the *step 1* of the wizard, *General*, select in the drop down menu the *Infrastructure Mapping* to be used, `ticket-monster-rhv`, add the name `ticket-monster-plan-app` and click *Next*.
+
image::migration_plan_2.png[Migration Plan 2]
+
[NOTE]
Keeping the default option will take us to the VM menu selector. For massive conversions a CSV file upload can be the right choice.

. In the *step 2* of the wizard, *VMs*, select the *jboss0* and *jboss1*  virtual machines, as the ones to be migrated.
+
image::migration_plan_3.png[Migration Plan 3]
+
[NOTE]
VM selector has a filter to help find a set of VMs within a long list. We may try filtering by the term `jboss`.

. In the *step 3* of the wizard, *Advanced Options*, we can assign *Pre* and *Post* migration playbooks to be executed during the migration. We will do this in a later part of the lab. For now, click *Next*
+
image::migration_plan_4.png[Migration Plan 4]

. In the *step 4* of the wizard, *Schedule*, select *Save migration plan to run later*. Click *Create*
+
image::migration_plan_5.png[Migration Plan 5]
+
[NOTE]
The migration plan can be run immediately, by choosing the other option.

. In the *step 5* of the wizard, *Results*, the message `Migration Plan: ticket-monster-plan-app has been saved` shall appear. Click *Close*.
+
image::migration_plan_6.png[Migration Plan 6]

. Back to the migration page we will see how the *Infrastructure Mapping* and *Migration Plan* are ready to be run
+
image::migration_plan_7.png[Migration Plan 7]

=== Launch Migration

. To launch the migration, while in the *Compute -> Migration* page, click on the *Migrate* button in the *ticket-monster-plan-app*.
+
image::migration_running_1.png[Migration Running 1]

. The migration will get initiated. All data is gathered and preflight checks are executed.
+
image::migration_running_2.png[Migration Running 2]

. The plan gets auto-approved. Migration starts
+
image::migration_running_3.png[Migration Running 3]

. Now the migration is executing. It takes some time for the pre-migration steps to be finished and the conversion process to start.
We can see the orchestration process in CloudForms logs
+
----
# ssh cf.example.com
# tail -f /var/www/miq/vmdb/log/automation.log
----
+
Once the pre-migration steps are finished and the conversion starts, each VM conversion process can be tracked in the Conversion Host:
+
----
# ssh kvm1.example.com
# tail -f /var/log/vdsm/import/v2v-import-*
----

. CloudForms Migration interface shows migration status too
+
image::migration_running_4.png[Migration Running 4]

. Clicking on the running plan info box will display the detailed info of the status
+
image::migration_running_5.png[Migration Running 5]

. Progress can be followed in this page
+
image::migration_running_6.png[Migration Running 6]

. For the time of the migration the JBoss EAP servers, `jboss0` and `jboss1` will be powered off in `vSphere`, migrated and then powered on in `RHV`.
+
image::migration_running_7.png[Migration Running 7]

. It is possible to check in the *RHV* admin portal under *Compute -> Virtual Machines* to monitor the status for the VM import as part of the migration process.
+
image::migration_running_8.png[Migration Running 8]

. Once the migration is finishing ...
+
image::migration_running_9.png[Migration Running 9]

. ... the VMs get powered up
+
image::migration_running_10.png[Migration Running 10]
+
image::migration_running_11.png[Migration Running 11]

. The migration gets completed.
+
image::migration_running_12.png[Migration Running 12]

. Let's check if the VMs are up and running using the following command:
+
----
# ansible app -m ping
----

. Migration can be reviewed in the Main Migration page in CloudForms
+
image::migration_running_15.png[Migration Running 15]

. Additionally the migration log can be downloaded and accessed post VM migration. This is useful for troubleshooting errors or just to check the migration details. It's worth mentioning that if the migration fails prior to the VM being migrated this log will not be available. To access the log navigate to Completed Plans, and click **Download Log** and then **Migration log** next to the desired VM.
+
image::migration_log_access.png[Migration Log Access]

.. Once the log is downloaded click to open:
+
image::migration_log.png[Migration Log]


