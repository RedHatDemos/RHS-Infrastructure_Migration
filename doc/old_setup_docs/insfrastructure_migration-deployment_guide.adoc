:scrollbar:
:data-uri:
:toc2:
:toclevels: 3
:imagesdir: images

== Infrastructure Migration 1.1 GA - Deployment Guide

:numbered:

== Overview

The field experience in migrating VMs from proprietary virtualization infrastructures to Red Hat infrastructure providers has been completed in several customized engagements. From the experience of these engagements and with the involvement of Engineering and User Experience and Design teams, a productized version of it is built, and included in the environment provided for this guide.

This guide intends to provide the information needed to perform a successful deployment of the Infrastructure Migration solution.
For the *official Infrastructure Migration Solution 1.0 documentation* please go link:https://access.redhat.com/documentation/en-us/red_hat_infrastructure_migration_solution/1.1/html/infrastructure_migration_solution_guide/[here]

The password to access all services is available link:https://mojo.redhat.com/docs/DOC-1174612-accessing-red-hat-solutions-lab-in-rhpds[here].

[WARNING]
This guide will not work properly in an environment previously used for the Infrastructure Migration Lab. A fresh new environment needs to be requested to follow this guide

== Base Requirements

What is needed to run the solution and, hopefully, why ... :-)

=== Requirements to access and perform this lab

* A computer with access to the Internet :-)
* Adobe Flash 15 or higher must be enabled in Firefox or Chromium used for vCenter connectivity
* SSH client (for Microsoft Windows users link:https://www.putty.org/[Putty] is recommended)
* Firefox 17 or higher, or Chromium / Chrome
+
[NOTE]
Grammarly plugin for Chrome causes problems when managing CloudForms. Please deactivate it while doing this lab.
+
[NOTE]
Internet Explorer is not recommended.

=== Product requirements

The minimum product versions required to run the solution are the following:
[cols="1,1",options="header"]
|=======
|Product |Version
|CloudForms |4.7.0+
|Red Hat Virtualization |4.2.7+
|Red Hat Enterprise Linux (Hypervisor) |7.6+
|Red Hat OpenStack Platform |13+
|VMware vSphere |5.5+
|=======

In a real-world escenario deployment, the software to install in the machines would be obtained through the official software channels, by subscribing them to Red Hat's CDN, or Red Hat Satellite. In this environment, to avoid having to register the machines, the following internal software repos are provided to work with instead:
[cols="1,1,1",options="header"]
|=======
|Product |Origin| Use
|RHEL 7 | http://storage.example.com/repos/rhel-7-server-rpms |RHEL 7.6 (virt-v2v updates needed)
|JBoss EAP 7|  http://storage.example.com/repos/jb-eap-7-for-rhel-7-server-rpms | JBoss EAP 7 rpm packages (for RHV and for JBoss VMs)
|RHEL 7 optional |  http://storage.example.com/repos/rhel-7-server-optional-rpms | RHEL 7.6 optional packages
|RHEL 7 extras | http://storage.example.com/repos/rhel-7-server-extras-rpms | RHEL 7.6 extras packages
|RHEL 7 supplementary | http://storage.example.com/repos/rhel-7-server-supplementary-rpms | RHEL 7.6 supplementary packages
|RHV 4 Manager | http://storage.example.com/repos/rhel-7-server-rhv-4.2-manager-rpms | RHV Manager 4.2 packages
|RHV 4 Manager Tools | http://storage.example.com/repos/rhel-7-server-rhv-4-manager-tools-rpms | RHV Manager 4.2 tools packages
|RHV 4 Agents | http://storage.example.com/repos/rhel-7-server-rhv-4-mgmt-agent-rpms | RHV 4 agents for RHEL
|Ansible 2 | http://storage.example.com/repos/rhel-7-server-ansible-2-rpms | Ansible 2.x packages
|RH Common | http://storage.example.com/repos/rhel-7-server-rh-common-rpms | RH common packages (agents)
|=======

== Deployment

=== CloudForms Deployment

The environment, as instantiated, is fully configured. In a simulated deployment we will have a pre-deployed VMware vSphere virtualization environment, a Red Hat Virtualization environment with, at least one hypervisor running RHEL.

In this Deployment Lab, a Cloudforms appliance is already provided, so there is no need to deploy one.
As a reference on how to deploy a CloudForms appliance on RHV and vSphere the following official documentation is available:

* link:https://access.redhat.com/documentation/en-us/red_hat_cloudforms/4.7/html/installing_red_hat_cloudforms_on_red_hat_virtualization/[Installing Red Hat CloudForms on Red Hat Virtualization]

* link:https://access.redhat.com/documentation/en-us/red_hat_cloudforms/4.7/html/installing_red_hat_cloudforms_on_vmware_vsphere/[Installing Red Hat CloudForms on VMware vSphere]

Also as a reference on how to configure the environment, the following official documentation is available:

* link:https://access.redhat.com/documentation/en-us/red_hat_infrastructure_migration_solution/1.1/html-single/infrastructure_migration_solution_guide/index[Infrastructure Migration Solution - Official Documentation]

In this lab we will have a CloudForms instance, that was deployed by downloading an appliance image and adding it to the environment.

The environment is completely configured, and an overview look at it, is recommended before starting.

=== CloudForms Reset

Once the overview is done, we can proceed by accessing, via SSH, the `workstation`. Use SSH your OPENTLC login name and private SSH key.

* Using a Unix/Linux system:
+
----
$ ssh -i /path/to/private_key <YOUR-OpenTLC-USERNAME-redhat.com>@workstation-<YOUR-GUID>.rhpds.opentlc.com
----

* Example for user 'batman' and GUID '1e37', using the default ssh private key:
+
----
$ ssh -i ~/.ssh/id_rsa batman-redhat.com@workstation-1e37.rhpds.opentlc.com
----

. Become `root` using the provided password:
+
----
$ sudo -i
----

We continue by running, in `workstation`, the playbook to unconfigure the deployed CloudForms:

----
# cd /root/RHS-Infrastructure_Migration/playbooks/
# ansible-playbook unconfigure.yml
----

The playbook will stop the CloudForms services, will reset the database, and restart the services. The playbook won't unconfigure `kvm1` or `conversion`, the currently configured conversion hosts, nor the RHV / RHOSP setup.

After CloudForms database reset, the users will be removed and the `admin` will have the *password reset* to the default appliance password (*smartvm*). We shall change that default password to the provided one by clicking in `update password` in the CloudForms login screen and filling up the new password fields:

image::cf_reset_password_1.png[CF Reset Password 1]
image::cf_reset_password_2.png[CF Reset Password 1]


The following link:../conf/[directory] contains repo files that can be used to consume the packages in the environment for the Manager, as well as for the Hypervisors, which are RHEL based.

== Enabling Red Hat Virtualization as Migration Target

=== Red Hat Virtualization VM Migration Workflow

image::migration_workflow.png[VM Migration Workflow]


. The Infrastructure Admin creates an *infrastructure mapping* and a virtual machine *migration plan* in CloudForms, and runs the migration plan.

. CloudForms locates the virtual machines to be migrated based on the *infrastructure mapping*.

. The ESXi host fingerprint is captured for authentication during the conversion process if the VDDK transport method is used. If SSH is used, a shared SSH key is used to connect to the ESX host where the virtual machine resides.

. Using the RHV attributes for the target environment, CloudForms *initiates communication* with the RHV *conversion host*.

. The RHV conversion host connects to the *source datastore* through the ESX host, using `virt-v2v-wrapper.py`, and streams the disk to be converted to the *target data domain* chosen in the infrastructure mapping using `virt-v2v`.

. After the *disk is converted*, the target *virtual machine is created* in RHV. During creation, the target virtual machine uses the source virtual machine’s metadata to maintain the virtual machine’s attributes (tags, power state, MAC address, CPU count, memory, disks, and virtual machine name) after migration.

. After the virtual machine is created, the *disk is attached* to the target virtual machine.

. *VM migration is complete*. The status displayed in CloudForms during the whole process.

[NOTE]
This is a fragment of the link:https://access.redhat.com/documentation/en-us/red_hat_infrastructure_migration_solution/1.1/html/infrastructure_migration_solution_guide/infrastructure_migration_solution_overview[Official Infrastructure Migration Solution Official Documentation]. Refer to it for the most updated information.

For more detail please take a look at the link:images/migration_workflow_rhv.png[full detailed vm migration and conversion workflow for RHV]

If you have doubts on the steps taking place during the conversion, please read the link:insfrastructure_migration-vm_conversion_faq.adoc[VM Conversion FAQ]

=== RHV Conversion Host Requirements

To perform the conversion task of the VMs during migration a conversion host is required.

For Red Hat Virtualization the architectural choices is to use RHEL Hypervisors as conversion hosts.

[cols="1,1,1",options="header"]
|=======
|Product |Origin| Use
|VDDK SDK |http://storage.example.com/repos/VMware-vix-disklib-6.5.2-6195444.x86_64.tar.gz |Virtual Disk Development Kit (VDDK)
|nbdkit SRPMS |http://storage.example.com/repos/rhel-7-server-rhv-4-mgmt-agent-source-rpms |nbdkit Source RPMS
|=======

=== Red Hat Virtualization: Add Virtualization Providers

Once CloudForms has been reset to a just installed state, the Virtualization providers have to be added to it. This can be done by login in with the default appliance password, and then following these steps:

. Navigate, in *Cloudforms* to  *Compute -> Infrastructure -> Providers*. Click on *Configuration -> Add a New Infrastructure Provider*.
+
image::cloudforms_add_providers_1.png[Add Providers 1]

. In the page *Add New Infrastructure Provider* type in Name `vSphere` and choose in *Type* dropdown menu `VMware vCenter`. Then under *Endpoints* in the space assigned as *Hostname* type `vcenter.example.com`, in *Username* type `root` and in *Password* use the <provided_password>. Click *Validate*.
+
image::cloudforms_add_providers_2.png[Add Providers 2]

. Once validated, a message stating *Credential validation was successful* shall appear. Click *Add*
+
image::cloudforms_add_providers_3.png[Add Providers 3]

. This will move to the *Infrastructure providers* page showing a message saying *Infrastructure Provider "vSphere" was saved*.
+
image::cloudforms_add_providers_4.png[Add Providers 4]

. Click on *Configuration -> Add a New Infrastructure Provider* again. In the page *Add New Infrastructure Provider* type, this time, Name `RHV` and choose in *Type* dropdown menu `Red Hat Virtualization`. Then under *Endpoints* in the space assigned as *Hostname* type `rhvm.example.com`, deactivate *Verify TLS Certificates*, then in *Username* type `admin@internal` and in *Password* use the <provided_password>. Click *Validate*.
+
image::cloudforms_add_providers_5.png[Add Providers 5]

. Once validated, a message stating *Credential validation was successful* shall appear. Click *Add*
+
image::cloudforms_add_providers_6.png[Add Providers 6]

. This will move, again, to the *Infrastructure providers* page showing a message saying *Infrastructure Provider "RHV" was saved*.
+
image::cloudforms_add_providers_7.png[Add Providers 7]

This way the two Virtualization providers are managed by CloudForms. Take some time to navigate the menus under *Compute -> Infrastructure*.

=== Adding Credentials to Conversion host in RHV

. On the `cf` system, go back to *Compute -> Infrastructure -> Hosts*.
+
image::conversion_host_1.png[Conversion Host 1]

. Click *kvm2*.
+
image::conversion_host_2b.png[Conversion Host 2]

. Select *Configuration -> Edit this item*.
+
image::conversion_host_8c.png[Conversion Host 8]

. Fill *Username* with `root` and *Password* with the provided one. Click *Validate*. Once the message "Credential validation was successful" appears click *Save*. This is needed to be able to connect to the conversion host and initiate the conversion.
+
image::conversion_host_9b.png[Conversion Host 9]

. Now the conversion host is ready.
+
image::conversion_host_10.png[Conversion Host 10]

[NOTE]
Remember to add also the credentials to access `kvm1.example.com`, as well as for `esx1.example.com` and `esx2.example.com`.

=== Installing tools in Conversion Host in RHV, and configuring it

We will use both hypervisors, `kvm1` and `kvm2`, as conversion hosts. Host `kvm1` is already configured. We will proceed to install `kvm2`.

The upstream playbooks an documenttion is available here: link:https://github.com/oVirt/ovirt-ansible-v2v-conversion-host/blob/master/docs/Ansible.md[ovirt-ansible-v2v-conversion-host]

In the `/usr/share/ovirt-ansible-v2v-conversion-host/playbooks` directory of the RHV Manager, the playbooks to install a conversion host are available:

----
[root@workstation ~]# ssh rhvm
[root@rhvm ~]# cd /usr/share/ovirt-ansible-v2v-conversion-host/playbooks
----

An inventory file `conversion_hosts_inventory.yml` has to be created, with the following content:

----
all:
  vars:
    ansible_ssh_private_key_file: /etc/pki/ovirt-engine/keys/engine_id_rsa
#    v2v_repo_rpms_name: "rhel-7-server-rhv-4-mgmt-agent-rpms"
#    v2v_repo_rpms_url: "http://storage.example.com/repos/rhel-7-server-rhv-4-mgmt-agent-rpms"
    v2v_repo_srpms_name: "rhel-7-server-rhv-4-mgmt-agent-source-rpms"
    v2v_repo_srpms_url: "http://storage.example.com/repos/rhel-7-server-rhv-4-mgmt-agent-source-rpms"
    v2v_vddk_package_name: "VMware-vix-disklib-6.5.2-6195444.x86_64.tar.gz"
    v2v_vddk_package_url: "http://storage.example.com/repos/VMware-vix-disklib-6.5.2-6195444.x86_64.tar.gz"
    manageiq_url: "https://cf.example.com"
    manageiq_username: "admin"
    manageiq_password: "to_be_provided"
    manageiq_zone_id: "1"
    manageiq_providers:
      - name: "RHV"
        connection_configurations:
          - endpoint:
              role: "default"
              verify_ssl: false
  hosts:
#    kvm1.example.com:
    kvm2.example.com:
      v2v_host_type: rhv
      v2v_transport_methods:
        - vddk
      manageiq_provider_name: "RHV"
----

[NOTE]
Do not forget to change the password `to_be_provided` for the one used to access CloudForms.  Unless you changed the admin password after resetting the environment, this will be the default password for the CloudForms appliance.

[TIP]
There is already a file created for you in the environment with some extra vars commented. The sample file is also available link:../scripts/conversion_hosts/conversion_hosts_inventory.yml[here]

Then the playbooks are run in the `/usr/share/ovirt-ansible-v2v-conversion-host/playbooks/` directory of the RHV Manager, `rhvm`.

There is a `conversion_host_check.yml` playbook that can be run and ensures that the installation is OK. You can run it before installing to *see how errors are reported*, as we will be running it on an uninstalled conversion host:

----
# cd /usr/share/ovirt-ansible-v2v-conversion-host/playbooks/
# ansible-playbook --inventory-file=conversion_hosts_inventory.yml conversion_host_check.yml
----

After that, the installation of tools can be performed by running the `conversion_host_enable.yml` playbook:

----
# pwd
/usr/share/ovirt-ansible-v2v-conversion-host/playbooks/
# ansible-playbook --inventory-file=conversion_hosts_inventory.yml conversion_host_enable.yml
----

It may be time to check again and ensure the tool installation went OK:

----
# pwd
/usr/share/ovirt-ansible-v2v-conversion-host/playbooks/
# ansible-playbook --inventory-file=conversion_hosts_inventory.yml conversion_host_check.yml
----

Let's see if it got added to CloudForms. First ssh into `cf.example.com` then, once there, run:

----
[root@cf ~]# vmdb
[root@cf vmdb]# rails c
** CFME 5.10.0.29, codename: Hammer
Loading production environment (Rails 5.0.7.1)
irb(main):001:0> pp ConversionHost.all
PostgreSQLAdapter#log_after_checkout, connection_pool: size: 5, connections: 1, in use: 1, waiting_in_queue: 0
[]
=> #<ActiveRecord::Relation []>
irb(main):002:0> pp ConversionHost.all
[#<ConversionHost:0x0000000000a23e88
  id: 1,
  name: "kvm2.example.com",
  address: nil,
  type: nil,
  resource_type: "Host",
  resource_id: 4,
  version: nil,
  max_concurrent_tasks: nil,
  vddk_transport_supported: true,
  ssh_transport_supported: false,
  created_at: Tue, 15 Jan 2019 14:44:53 UTC +00:00,
  updated_at: Tue, 15 Jan 2019 14:44:53 UTC +00:00,
  concurrent_transformation_limit: nil,
  cpu_limit: nil,
  memory_limit: nil,
  network_limit: nil,
  blockio_limit: nil>]
=> #<ActiveRecord::Relation [#<ConversionHost id: 1, name: "kvm2.example.com", address: nil, type: nil, resource_type: "Host", resource_id: 4, version: nil, max_concurrent_tasks: nil, vddk_transport_supported: true, ssh_transport_supported: false, created_at: "2019-01-15 14:44:53", updated_at: "2019-01-15 14:44:53", concurrent_transformation_limit: nil, cpu_limit: nil, memory_limit: nil, network_limit: nil, blockio_limit: nil>]>

----

=== RHV Conversion Host Configuration in CloudForms

To create a conversion host, until we have an API endpoint for that, we need to do some steps in Rails console. So first, let's connect to it using the `rails` console in CloudForms:

----
# ssh cf
# vmdb
# rails c
----

Now, that we are connected, let's check if the conversion host is cofigured.

----
[root@cf vmdb]# rails c
** CFME 5.10.0.29, codename: Hammer
Loading production environment (Rails 5.0.7.1)
irb(main):001:0> pp ConversionHost.all
----

If not, we can manually configure it. We may use this procedure to re-add `kvm1.example.com` procedure is the following:

----
irb> res = Host.find_by(name: 'kvm1.example.com')
irb> conversion_host = ConversionHost.create(name: res.name, resource: res)
----

[TIP]
Remember to use the name of the host as it is recognized in CloudForms


Then, we can set the supported transport methods: VDDK and/or SSH, with VDDK preferred for performance.

----
irb> conversion_host.vddk_transport_supported = true
----

We can also set the maximum number of concurrent migrations running on this conversion host:

----
irb> conversion_host.max_concurrent_tasks = 5
----

And never forget to save the object to serialize it in the database:

----
irb> conversion_host.save
----


To delete the conversion host with `id` *1*, simply run the following in the rails console:

----
irb> ConversionHost.delete(1)
----

== Enabling Red Hat OpenStack Platform as Migration Target

=== Red Hat OpenStack Platform VM Migration Workflow

image::osp_arch_diagram.png[OSP Migration Workflow]

. The Infrastructure Admin creates an *infrastructure mapping* and a virtual machine *migration plan* in CloudForms, and runs the migration plan.

. CloudForms uses the migration plan to locate the virtual machines to be migrated.
+
[NOTE]
====
Source virtual machines must be powered on for the migration. OpenStack by design cannot create powered-off VMs.
====
. If VDDK transformation is used, the ESXi host fingerprint is captured for authentication during the virtual machine conversion process.
. Using the OpenStack Platform attributes defined for the target environment, CloudForms initiates communication with the conversion hosts.
. The conversion host connects to the source datastore through the ESXi host, using `virt-v2v-wrapper`, and streams the disks to be converted to the target block storage, using `virt-v2v`. The conversion host creates volumes in the block storage, attaches them to itself, and converts the source disks.
. Once the disks are converted, `virt-v2v` detaches the volumes from the conversion host. `virt-v2v-wrapper` creates the target instance in the OpenStack Platform environment with the converted disks, using the flavor and security group defined in the migration plan and the network(s) defined in the infrastructure mapping.
. The disks mapped in the block storage are attached to the instance and the instance is powered on.
. The migration process is complete and the migration plan’s status is displayed in CloudForms.

=== Red Hat OpenStack Platform Conversion Host Requirements

For Red Hat OpenStack Platform, a Conversion Host Instance running RHEL will be used.
VDDK SDK will have to be downloaded separately.

[cols="1,1,1",options="header"]
|=======
|Product |Origin| Use
|VDDK SDK |http://storage.example.com/repos/VMware-vix-disklib-6.5.2-6195444.x86_64.tar.gz |Virtual Disk Development Kit (VDDK)
|V2V RHOSP Appliance| stack@director:/home/stack/images/rhosp-v2v-appliance-14.0-20181214.1.x86_64.qcow2
|=======

=== Red Hat OpenStack Platform: Add Infrastructure Provider

==== Adding Red Hat OpenStack Platform Director to Cloudforms

[NOTE]
====
The following steps can be done later, after a conversion host instance has been created in OpenStack.
====
. Navigate to *Compute* -> *Infrastructure* -> *Providers*
. Click *Configuration* -> then click *Add a New Infrastructure Provider*
+
image::cloudforms_add_providers_director_1.png[Add Providers Director 1]

. Enter the *Name* of the provider to add as `OpenStack Director`.
. Select *OpenStack Platform Director* from the Type list.
. Select the API Version of your OpenStack provider’s Keystone service from the list. In this case `Keystone v3`
.. Set the *Keystone V3 Domain ID* to `default`
. In the *Default* tab, under Endpoints, configure the host and authentication details of your OpenStack provider:
.. Select a *Security Protocol* method as `Non-SSL`
.. Enter the Host Name or IP address of the provider: `10.100.0.20`.
.. In the *Username* field, enter *'admin'* as the name of an OpenStack user with privileged access. Then, provide its corresponding password in the *Password* and *Confirm Password* fields.
.. Click Validate to confirm Red Hat CloudForms can connect to the OpenStack provider.
+
image::cloudforms_add_providers_director_2.png[Add Providers Director 2]

. Next we will configure *SSH access* to hosts which is needed later when enabling *conversion host* for OpenStack. Click on *RSA keypair* tab in the *Endpoints* section
.. *Username* should be set to `root`.
.. Upload the *ssh key* available in `workstation:/root/.ssh/id_rsa`. (Note: you will need to copy it to your own workstation)
+
image::cloudforms_add_providers_director_3.png[Add Providers Director 3]
+
image::cloudforms_add_providers_director_4.png[Add Providers Director 4]

==== Adding Red Hat OpenStack Platform to Cloudforms

. Navigate to *Compute* -> *Clouds* -> *Providers*
+
image::cloudforms_add_providers_osp_1.png[Add Providers OSP 1]

. Click *Configuration* -> then click *Add a New Cloud Provider*
+
image::cloudforms_add_providers_osp_2.png[Add Providers OSP 2]

. Enter the *Name* of the provider to add as `OpenStack`.
. Select *OpenStack* from the Type list.
. Select the API Version of your OpenStack provider’s Keystone service from the list. In this case `Keystone v3`
.. Set the *Keystone V3 Domain ID* to `default`
. In the *Default* tab, under Endpoints, configure the host and authentication details of your OpenStack provider:
.. Select a *Security Protocol* method as `Non-SSL`
.. Enter the Host Name or IP address of the provider: `horizon.example.com`.
.. In the *Username* field, enter `admin` as the name of an OpenStack user with privileged access. Then, provide its corresponding password in the *Password* and *Confirm Password* fields.
.. Click *Validate* to confirm Red Hat CloudForms can connect to the OpenStack provider.
+
image::cloudforms_add_providers_osp_3.png[Add Providers OSP 3]

.. Once OSP provider is validated, click add 
+
image::cloudforms_add_providers_osp_4.png[Add Providers OSP 4]
+
image::cloudforms_add_providers_osp_5.png[Add Providers OSP 5]

. Next we will configure *SSH access* to hosts which is needed later when enabling *conversion host* for OpenStack. Click on *RSA keypair* tab in the *Endpoints* section
.. *Username* should be set to `root`.
.. Upload the *ssh key* available in `workstation:/root/.ssh/id_rsa`. (Note: you will need to copy it to your own workstation) 
+
image::cloudforms_add_providers_osp_6.png[Add Providers OSP 6]
+
image::cloudforms_add_providers_osp_7.png[Add Providers OSP 7]


=== Red Hat OpenStack Platform Conversion Host Installation

Configuring the conversion hosts for migration involves the following key steps:

. Downloading and copying the VDDK package
. Creating an Ansible inventory file
. Configuring the conversion hosts and adding them to CloudForms
. Validating the configuration

----
[root@workstation ~]# ssh conversion
[root@conversion ~]# cd /usr/share/ovirt-ansible-v2v-conversion-host/playbooks/
----


An inventory file `conversion_hosts_inventory.yml` has to be created, with the following content:

----
all:
  vars:
    ansible_ssh_private_key_file: /root/.ssh/id_rsa
#    v2v_repo_rpms_name: "rhel-7-server-rhv-4-mgmt-agent-rpms"
#    v2v_repo_rpms_url: "http://storage.example.com/repos/rhel-7-server-rhv-4-mgmt-agent-rpms"
#    v2v_repo_srpms_name: "rhel-7-server-rhv-4-mgmt-agent-source-rpms"
#    v2v_repo_srpms_url: "http://storage.example.com/repos/rhel-7-server-rhv-4-mgmt-agent-source-rpms"
    v2v_vddk_package_name: "VMware-vix-disklib-6.5.2-6195444.x86_64.tar.gz"
    v2v_vddk_package_url: "http://storage.example.com/repos/VMware-vix-disklib-6.5.2-6195444.x86_64.tar.gz"
    manageiq_url: "https://cf.example.com"
    manageiq_username: "admin"
    manageiq_password: "to_be_provided"
    manageiq_zone_id: "1"
    manageiq_providers:
      - name: "OSP"
        connection_configurations:
          - endpoint:
              role: "default"
              verify_ssl: false
  hosts:
    conversion.example.com:
      v2v_host_type: openstack
      v2v_transport_methods:
        - vddk
      manageiq_provider_name: "OpenStack"
----

[WARNING]
Do not forget to change the password `to_be_provided` for the one used to access CloudForms

Then the playbooks are run in the `/usr/share/ovirt-ansible-v2v-conversion-host/playbooks/` directory of the Conversion Host Image, in this case deployed as `conversion`.

There is a `conversion_host_check.yml` playbook that can be run and ensures that the installation is OK. You can run it before installing to *see how errors are reported*, as we will be running it on an uninstalled conversion host:

----
# cd /usr/share/ovirt-ansible-v2v-conversion-host/playbooks/
# ansible-playbook --inventory-file=conversion_hosts_inventory.yml conversion_host_check.yml
----

After that, the installation of tools can be performed by running the `conversion_host_enable.yml` playbook:

----
# pwd
/usr/share/ovirt-ansible-v2v-conversion-host/playbooks/
# ansible-playbook --inventory-file=conversion_hosts_inventory.yml conversion_host_enable.yml
----

It may be time to check again and ensure the tool installation went OK:

----
# pwd
/usr/share/ovirt-ansible-v2v-conversion-host/playbooks/
# ansible-playbook --inventory-file=conversion_hosts_inventory.yml conversion_host_check.yml
----

Also on the CloudForms side:

----
[root@cf vmdb]# rails c
** CFME 5.10.0.29, codename: Hammer
Loading production environment (Rails 5.0.7.1)
irb(main):001:0> pp ConversionHost.all
----

[NOTE]
In this version of the appliance the registration of it in CloudForms is not availabler, therefore, a manual registration will be required.  

Or via CloudForms web UI:

. Navigate to https://cf-UUID.rhpds.opentlc.com/api/conversion_hosts
. Use CloudForms `admin` username and password to authenticate.
. You will be presented with a JSON output listing all the conversion hosts.

=== RHOSP Conversion Host Configuration in CloudForms

To manually configure a conversion host in CloudForms, we need to do some steps in Rails console. So first, let's connect to it:

----
# ssh cf
# vmdb
# rails c
----

Now, that we are connected, we have two types of conversion host that we can create: a RHV host or an OpenStack instance. Let's see how to create them. The procedure is similar for both:

----
irb> res = Vm.find_by(name: 'conversion')
irb> conversion_host = ConversionHost.create(name: res.name, resource: res)
----

Then, we can set the supported transport methods: VDDK and/or SSH, with VDDK preferred for performance.

----
irb> conversion_host.vddk_transport_supported = true
irb> conversion_host.ssh_transport_supported = true
----

We can also set the maximum number of concurrent migrations running on this conversion host:

----
irb> conversion_host.max_concurrent_tasks = 5
----

And don't forget to save it in the database:

----
irb> conversion_host.save
----

== Adding Ansible Playbooks

. Enable in the top right corner *Administrator | EVM -> Configuration* the *Embedded Ansible* role. 
+
image::cf_enable_embedded_ansible_1.png[Enable Embedded Ansible 1]
+
image::cf_enable_embedded_ansible_2.png[Enable Embedded Ansible 2]

. The procedure to enable *Embedded Ansible* takes from 7 to 9 minutes (great moment to grab a coffee!!). You may check when the feature is fully enabled, and the service running, in the *diagnostics* accordion -> *workers* tab. The `Embedded Ansible Worker` must appear there as running, otherwise the following steps will not be possible.
+
image::cf_enable_embedded_ansible_3.png[Enable Embedded Ansible 3]

. In *Automation -> Ansible -> Credentials*, click in *Configuration -> Add new Credential*. Use *name* `ticket-monster-vm-creds`, select *Type* `machine` and fill *Username* with `root` and the *Password* with the `to_be_provided` password.
+
image::cf-ansible_add_credentials_1.png[Ansible Add Credentials 1]
+
image::cf-ansible_add_credentials_2.png[Ansible Add Credentials 2]
+
image::cf-ansible_add_credentials_3.png[Ansible Add Credentials 3]
+
image::cf-ansible_add_credentials_4.png[Ansible Add Credentials 4]
+
image::cf-ansible_add_credentials_5.png[Ansible Add Credentials 5]

. In *Automation -> Ansible -> Repositories*, click in *Configuration -> Add new Repository*. Use *name* `ansible-migration-repo` and the URL `https://github.com/mperezco/v2v-ansible-test-playbooks`. Select `update on launch` and click `add`
+
image::cf-ansible_add_repository_1.png[Ansible Add Repository 1]
+
image::cf-ansible_add_repository_2.png[Ansible Add Repository 2]
+
image::cf-ansible_add_repository_3.png[Ansible Add Repository 3]
+
image::cf-ansible_add_repository_4.png[Ansible Add Repository 4]
+
image::cf-ansible_add_repository_5.png[Ansible Add Repository 5]

. In *Automation -> Ansible -> Playbooks* we can check that the content of the repo has been added and is available
+
image::cf-ansible_check_playbooks_1.png[Ansible Check Repository 1]
+
image::cf-ansible_check_playbooks_2.png[Ansible Check Repository 2]

. To make the playbooks available in CloudForms, we will add a *Catalog Item*. Go to *Services -> Catalogs* 
+
image::cf-add_catalog_item_1.png[CF Add Catalog Item 1]

. Click on *Configuration -> Add a new Catalog Item*
+
image::cf-add_catalog_item_2.png[CF Add Catalog Item 2]

. Select as `Catalog item Type` *Ansible Playbook*
+
image::cf-add_catalog_item_3.png[CF Add Catalog Item 3]

. Insert *Name* as `rhel-premigrate-playbook`, and add a proper *Description*. Then in the *Provisioning* tab select: *Repository* -> `ansible-migration-repo` ; *Playbook* -> `pre_migration_rhel.yml` ; *Machine Credential* -> `ticket-monster-vm-creds` ...
+
image::cf-add_catalog_item_4.png[CF Add Catalog Item 4]

. Continue the selection with *Logging Output* and *Verbosity*. In *Dialog* select *Create New* and add a name like `migration-dialog`. Click *Add*
+
image::cf-add_catalog_item_5.png[CF Add Catalog Item 5]

. The *Catalog Item* will be added
+
image::cf-add_catalog_item_6.png[CF Add Catalog Item 6]


== Testing the Environment

The environment is ready to perform a migration. To test it, follow the link:insfrastructure_migration-lab_guide.adoc[Lab Instructions] using `kvm2` as the Conversion Host.

== Advanced and Experimental

In case you may want to know more about the environment you can check the link:insfrastructure_migration-advanced_experimental.adoc[Advanced and Experimental exercises]

== Troubleshooting the Migration Solution

For troubleshooting the environment please read the link:insfrastructure_migration-troubleshooting.adoc[Troubleshooting the Migration Solution] document
