:scrollbar:
:data-uri:
:toc2:
:imagesdir: images

== Red Hat Solutions: IT Optimization - Infrastructure Migration v2 Notes

:numbered:

== Overview

The field experience in migrating VMs from propietary virtualization infrastructures to open virtualization infrastructures has been consolidated in several real life customized engagements. From the experience of these engagements, and with the involvement of Engineering and User Experience and Design teams, a productized version of it is being built.

This document intends to capture the information derived from the experience of building the solution and putting it into a reproducible environment.

=== Configuring Autostart for VMs in ESXi

----
~ # vim-cmd vmsvc/getallvms
Vmid    Name                File                  Guest OS      Version   Annotation
8      jboss1   [Datastore] jboss1/jboss1.vmx   rhel7_64Guest   vmx-10              
9      db       [Datastore] db/db.vmx           rhel7_64Guest   vmx-10              
~ # vim-cmd hostsvc/autostartmanager/update_autostartentry 8 PowerOn 45 2 GuestShutDown 1 yes
2Updated AutoStart order.
~ # vim-cmd vmsvc/getallvms
Vmid    Name                File                  Guest OS      Version   Annotation
8      jboss1   [Datastore] jboss1/jboss1.vmx   rhel7_64Guest   vmx-10              
9      db       [Datastore] db/db.vmx           rhel7_64Guest   vmx-10              
~ # vim-cmd hostsvc/autostartmanager/get_autostartseq
(vim.host.AutoStartManager.AutoPowerInfo) [
   (vim.host.AutoStartManager.AutoPowerInfo) {
      dynamicType = <unset>, 
      key = 'vim.VirtualMachine:9', 
      startOrder = 1, 
      startDelay = 15, 
      waitForHeartbeat = "yes", 
      startAction = "PowerOn", 
      stopDelay = 1, 
      stopAction = "PowerOff", 
   }, 
   (vim.host.AutoStartManager.AutoPowerInfo) {
      dynamicType = <unset>, 
      key = 'vim.VirtualMachine:8', 
      startOrder = 2, 
      startDelay = 45, 
      waitForHeartbeat = "yes", 
      startAction = "PowerOn", 
      stopDelay = 1, 
      stopAction = "PowerOff", 
   }
]
----

=== Building CloudForms

CloudForms is the product built from the code of its upstream project ManageIQ. There will be references to ManageIQ as the place where the changes are performed to get them into the product. 

Initially ManageIQ will be deployed using the following playbooks:

link:https://github.com/fdupont-redhat/v2v-demolab-ansible[v2v-demolab-ansible]

It requires a VM with:

* CentOS 7.4 or RHEL 7.4 
** Software Collections are needed to use PostgreSQL 9.5
** `# subscription-manager repos --disable='*' --enable='rhel-7-server-rpms' --enable='rhel-7-server-rh-common-rpms' --enable='rhel-server-rhscl-7-rpms' --enable='rhel-7-server-optional-rpms'`

* EPEL installed 
** `# yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm`

* Three HDD
** Disk1: Operating System and CloudForms 
** Disk2: PostgreSQL database
** Disk3: Logs

Once the VM is ready the playbooks need to be run, whether from the VM itself or from another VM with Ansible. Tested with Ansible version 2.4

The Playbooks can help you register the VM and assign the proper repos. For a VM with repos configured I used the following `install.yml` in `v2v-demolab-ansible`

----
all:
  children:
    ManageIQ:
      children:
        database:
          hosts:
            cf.example.com:
              manageiq_postgresql_disk: /dev/vdb
        ui:
          hosts:
            cf.example.com:
        worker:
          hosts:
            cf.example.com:
              manageiq_logs_disk: /dev/vdc
  hosts:
----

[NOTE]
The `vars:` section, when not including any var, needs to be commented to run.

[TIP]
Disks for logs and database need to be different. If configured with the same one, playbook will fail.

*^^^DEPRECATED BY USING NIGHTLY BUILDS^^^*

=== RHV Requirements

Red Hat Virtualization, referred as RHV, the product built from the code of its upstream project oVirt. In this case even the changes are done upstream the software used to build the environment is derived from the engineering build system.

The location of the packages are the following:
[cols="1,1,1",options="header"]
|=======
|Product |Origin| Use
|RHEL 7.5 |http://download.eng.bos.redhat.com/rel-eng/latest-RHEL-7.5/compose/Server/$basearch/os/ |RHEL 7.5.z beta builds (Libvirt changes needed)
|RHEL 7.5 optional |http://download.eng.bos.redhat.com/rel-eng/latest-RHEL-7.5/compose/Server-optional/$basearch/os/ | RHEL 7.5 optional packages beta builds
|RHEL 7.5 extras |http://download.eng.bos.redhat.com/rel-eng/latest-EXTRAS-7-RHEL-7.5/compose/Server/$basearch/os/ | RHEL 7.5 extras packages beta builds
|RHV Hypervisor packages for RHEL 7.5 |http://download.eng.bos.redhat.com/rel-eng/repos/rhevh-rhel-7.5-candidate/$basearch/ |RHV Hypervisor beta builds for RHEL 7.5
|RHV Manager 4.2.2 |http://bob.eng.lab.tlv.redhat.com/builds/4.2/rhv-4.2.2-3/el$releasever |RHV Manager 4.2.2 beta builds
|JBoss EAP 7.1 |http://download.devel.redhat.com/devel/candidates/JBEAP/composing/latest-JBEAP-7.1-RHEL-7/compose/Server/$basearch/os/ |RHV Manager depends on it
|=======

The following link:https://github.com/RedHatDemos/RHS-Optimize_IT-Infrastructure_Migration/blob/master/notes_v2/rhv.repo:[repo file] was used to retrieve the packages using `reposync` tool (`yum-utils` package)

----
# reposync --config=/root/rhv.repo --download_path=/mnt/  --download-metadata --downloadcomps --newest-only
----

=== Conversion Host Requirements

To perform the conversion task of the VMs during migration a conversion host is required. One of the architectural choices is to use RHEL-H Hypervisors as conversion hosts, which is the one we will use here.

[cols="1,1,1",options="header"]
|=======
|Product |Origin| Use
|VDDK SDK |http://10.19.2.1/vddk/VMware-vix-disklib-6.5.2-6195444.x86_64.tar.gz |Virtual Disk Development Kit (VDDK)
|VDDK RPMs |http://10.19.2.1/rpms/v2v-nbdkit-rpms |Virtual Disk Development Kit (VDDK) RPMs
|VDDK SRPMs |http://10.19.2.1/rpms/v2v-nbdkit-src-rpms |Virtual Disk Development Kit (VDDK) SRPMs
|=======

== Installation

=== ManageIQ/CloudForms Installation

The installation creates the user `miq` with home in `/home/miq` where all CloudForms software is deployed. This will change in the future to use the common paths.

In the the home you will find the following directories with github origins:
[cols="1,1,1",options="header"]
|=======
|Directory |Origin| Use
|manageiq |https://github.com/ManageIQ/manageiq.git |Main ManageIQ backend code (CloudForms Upstream)
|manageiq-ui-classic |https://github.com/ManageIQ/manageiq-ui-classic.git |Main ManageIQ UI code (CloudForms Upstream)
|miq_v2v_ui_plugin |https://github.com/priley86/miq_v2v_ui_plugin.git |Infra Migration Plugin for ManageIQ (CloudForms Upstream)
|v2v-automate |https://github.com/fdupont-redhat/v2v-automate |v2v ManageIQ classes and methods
|=======

Once the ManageIQ instance is deployed the Classes and methods need to be added:

----
# su - miq
$ mkdir /tmp/automate
$ git clone https://github.com/fdupont-redhat/v2v-automate.git /tmp/automate/V2V
$ cd /home/miq/manageiq
$ bundle exec rake evm:automate:import DOMAIN=V2V IMPORT_DIR=/tmp/automate PREVIEW=false ENABLED=true
----
*^DEPRECATED WITH NIGHTLTY BUILDS^*

=== Conversion Host Installation

We will use both hypervisors, `kvm0` and `kvm1`, as conversion hosts

In the `root` directory of the Workstation, used as *Ansible* main host, the following repo is cloned:
[cols="1,1,1",options="header"]
|=======
|Directory |Origin| Use
|manageiq |https://github.com/fdupont-redhat/v2v-transformation_host-ansible.git |Main ManageIQ backend code (CloudForms Upstream)
|=======

The file `inventory.yml` is created, in the `v2v-transformation_host-ansible` directory, with the following content:

----
all:
  vars:
    v2v_repo_rpms_name: "v2v-nbdkit-rpms"
    v2v_repo_rpms_url: "http://storage.example.com/repos/v2v-nbdkit-rpms"
    v2v_repo_srpms_name: "v2v-nbdkit-src-rpms"
    v2v_repo_srpms_url: "http://storage.example.com/repos/v2v-nbdkit-src-rpms"
    v2v_vddk_package_name: "VMware-vix-disklib-6.5.2-6195444.x86_64.tar.gz"
    v2v_vddk_package_url: "http://storage.example.com/repos/VMware-vix-disklib-6.5.2-6195444.x86_64.tar.gz"
  hosts:
    kvm0.example.com:
    kvm1.example.com:
----

Then the playbooks are run. To check:

----
# ansible-playbook --inventory-file=inventory.yml transformation_host_check.yml 
----

After that, and if it all went OK, the installation:

----
# ansible-playbook --inventory-file=inventory.yml transformation_host_enable.yml 
----
